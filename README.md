# План проекта: Локальная система потокового распознавания речи

## Общее описание(Начальный план работ, сгенерировано LLM)
**Цель:** Создать систему, которая в реальном времени захватывает аудиопоток с микрофона, обрабатывает его и распознает речь с помощью локально развернутой ML-модели (например, Whisper, Vosk, Silero).

---
## Роль 1: Инженер по захвату и предобработке аудиопотока

### Задачи, связанные со звуком:

- **Захват аудиопотока с микрофона**
  - Настройка `PyAudio`/`SoundDevice` для непрерывного захвата
  - Определение оптимальных параметров: sample rate (16000/48000 Гц), bit depth (16 бит), channels (моно)
  - Реализация кольцевого буфера для потокового чтения данных

- **Предобработка аудиосигнала**
  - Реализация фильтров для удаления шума (высокочастотный, полосовой)
  - Нормализация громкости и автоматическая регулировка уровня сигнала
  - Спектральное вычитание для подавления фонового шума
  - Обнаружение голосовой активности (VAD) с `webrtcvad`

- **Подготовка данных для модели**
  - Конвертация форматов (стерео → моно, resampling при необходимости)
  - Разбивка на фреймы оптимального размера для модели распознавания

**Технологии:** PyAudio, NumPy, SciPy, webrtcvad, librosa

---

## Роль 2: Инженер по развертыванию и интеграции ML-модели

### Задачи, связанные со звуком:

- **Выбор и настройка модели распознавания**
  - Сравнение моделей: Whisper, Vosk, Silero V3
  - Установка и настройка выбранной модели локально
  - Оптимизация модели для CPU/GPU инференса

- **Создание API для модели**
  - Разработка FastAPI/Flask сервера для инференса
  - Реализация эндпоинтов для потокового и пакетного распознавания
  - Настройка форматов ввода/вывода (WAV, PCM, FLAC)

- **Интеграция с аудиопотоком**
  - Прием аудиобуферов от модуля захвата
  - Преобразование сырого аудио в формат, требуемый моделью
  - Организация асинхронной обработки запросов к модели

**Технологии:** PyTorch, Transformers, FastAPI, ONNX Runtime, Whisper/Vosk

---


## Роль 3: Инженер по пост-обработке и интерфейсу

### Задачи, связанные со звуком:

- **Пост-обработка распознанного текста**
  - Расстановка пунктуации с помощью отдельной ML-модели
  - Капитализация текста (заглавные буквы в начале предложений)
  - Фильтрация ложных срабатываний и артефактов распознавания

- **Визуализация и интерфейс**
  - Создание GUI (Tkinter/PyQt) или веб-интерфейса
  - Реализация "живых" субтитров с постепенным появлением текста
  - Визуализация уровня громкости и VAD-статуса
  - Отображение уверенности модели в распознавании

- **Управление выводом**
  - Синхронизация текста с временными метками из аудио
  - Реализация сохранения результатов (текст + аудио)
  - Экспорт в форматы субтитров (SRT, VTT)

**Технологии:** Tkinter/PyQt, Flask, модели пунктуации, pandas

---


## Общая архитектура потока данных

```
Микрофон → Захват звука → Предобработка → ML-модель → Пост-обработка → Интерфейс
```

## Этапы реализации

1. **Прототип (2 недели)**
   - Базовый захват звука + простая модель распознавания
   - Вывод текста в консоль

2. **Базовая функциональность (3 недели)**
   - Добавление VAD и предобработки
   - Создание API для модели
   - Простой GUI

3. **Оптимизация (2 недели)**
   - Улучшение качества распознавания
   - Добавление пунктуации
   - Оптимизация производительности

4. **Полировка (1 неделя)**
   - Улучшение интерфейса
   - Тестирование и багфиксинг

## Критерии успеха

- Задержка распознавания < 2 секунд
- Точность распознавания > 85% для чистого голоса
- Стабильная работа в реальном времени
- Удобный интерфейс для пользователя